{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVG_WND_SPEED</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>FOG</th>\n",
       "      <th>THUNDER</th>\n",
       "      <th>SLEET_OR_HAIL</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444211</td>\n",
       "      <td>1444211</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444212</td>\n",
       "      <td>1444212</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444213</td>\n",
       "      <td>1444213</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444214</td>\n",
       "      <td>1444214</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444215</td>\n",
       "      <td>1444215</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444216 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        DATE  start_station_id  hour_of_day  COUNT  \\\n",
       "0                 0  2015-04-23            3004.0           10      5   \n",
       "1                 1  2015-04-23            3004.0           12      3   \n",
       "2                 2  2015-04-23            3004.0           13      2   \n",
       "3                 3  2015-04-23            3004.0           14      1   \n",
       "4                 4  2015-04-23            3004.0           15      5   \n",
       "...             ...         ...               ...          ...    ...   \n",
       "1444211     1444211  2019-09-30            3210.0            9      3   \n",
       "1444212     1444212  2019-09-30            3210.0           10      1   \n",
       "1444213     1444213  2019-09-30            3210.0           11      1   \n",
       "1444214     1444214  2019-09-30            3210.0           12      1   \n",
       "1444215     1444215  2019-09-30            3210.0           17      4   \n",
       "\n",
       "         AVG_WND_SPEED  PRCP  SNOW  SNOW_DEPTH  TAVG  TMAX  TMIN  FOG  \\\n",
       "0                15.21   0.0   0.0         0.0  48.0    52    43  0.0   \n",
       "1                15.21   0.0   0.0         0.0  48.0    52    43  0.0   \n",
       "2                15.21   0.0   0.0         0.0  48.0    52    43  0.0   \n",
       "3                15.21   0.0   0.0         0.0  48.0    52    43  0.0   \n",
       "4                15.21   0.0   0.0         0.0  48.0    52    43  0.0   \n",
       "...                ...   ...   ...         ...   ...   ...   ...  ...   \n",
       "1444211           7.61   0.0   0.0         0.0  69.0    75    62  0.0   \n",
       "1444212           7.61   0.0   0.0         0.0  69.0    75    62  0.0   \n",
       "1444213           7.61   0.0   0.0         0.0  69.0    75    62  0.0   \n",
       "1444214           7.61   0.0   0.0         0.0  69.0    75    62  0.0   \n",
       "1444215           7.61   0.0   0.0         0.0  69.0    75    62  0.0   \n",
       "\n",
       "         THUNDER  SLEET_OR_HAIL  month  year  \n",
       "0            0.0            0.0      4  2015  \n",
       "1            0.0            0.0      4  2015  \n",
       "2            0.0            0.0      4  2015  \n",
       "3            0.0            0.0      4  2015  \n",
       "4            0.0            0.0      4  2015  \n",
       "...          ...            ...    ...   ...  \n",
       "1444211      0.0            0.0      9  2019  \n",
       "1444212      0.0            0.0      9  2019  \n",
       "1444213      0.0            0.0      9  2019  \n",
       "1444214      0.0            0.0      9  2019  \n",
       "1444215      0.0            0.0      9  2019  \n",
       "\n",
       "[1444216 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVG_WND_SPEED</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>FOG</th>\n",
       "      <th>THUNDER</th>\n",
       "      <th>SLEET_OR_HAIL</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>177784</td>\n",
       "      <td>177784</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177785</td>\n",
       "      <td>177785</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177786</td>\n",
       "      <td>177786</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177787</td>\n",
       "      <td>177787</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177788</td>\n",
       "      <td>177788</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>11.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188920</td>\n",
       "      <td>188920</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188921</td>\n",
       "      <td>188921</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188922</td>\n",
       "      <td>188922</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>3086.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188923</td>\n",
       "      <td>188923</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188924</td>\n",
       "      <td>188924</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>3088.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11141 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0        DATE  start_station_id  hour_of_day  COUNT  \\\n",
       "177784      177784  2016-01-01            3004.0           13      2   \n",
       "177785      177785  2016-01-01            3004.0           14      1   \n",
       "177786      177786  2016-01-01            3004.0           15      2   \n",
       "177787      177787  2016-01-01            3004.0           17      1   \n",
       "177788      177788  2016-01-01            3004.0           18      1   \n",
       "...            ...         ...               ...          ...    ...   \n",
       "188920      188920  2016-01-31            3086.0           16      1   \n",
       "188921      188921  2016-01-31            3086.0           17      1   \n",
       "188922      188922  2016-01-31            3086.0           18      2   \n",
       "188923      188923  2016-01-31            3088.0           14      2   \n",
       "188924      188924  2016-01-31            3088.0           15      1   \n",
       "\n",
       "        AVG_WND_SPEED  PRCP  SNOW  SNOW_DEPTH  TAVG  TMAX  TMIN  FOG  THUNDER  \\\n",
       "177784          11.63   0.0   0.0         0.0   NaN    43    34  0.0      0.0   \n",
       "177785          11.63   0.0   0.0         0.0   NaN    43    34  0.0      0.0   \n",
       "177786          11.63   0.0   0.0         0.0   NaN    43    34  0.0      0.0   \n",
       "177787          11.63   0.0   0.0         0.0   NaN    43    34  0.0      0.0   \n",
       "177788          11.63   0.0   0.0         0.0   NaN    43    34  0.0      0.0   \n",
       "...               ...   ...   ...         ...   ...   ...   ...  ...      ...   \n",
       "188920           5.37   0.0   0.0         3.9   NaN    58    30  0.0      0.0   \n",
       "188921           5.37   0.0   0.0         3.9   NaN    58    30  0.0      0.0   \n",
       "188922           5.37   0.0   0.0         3.9   NaN    58    30  0.0      0.0   \n",
       "188923           5.37   0.0   0.0         3.9   NaN    58    30  0.0      0.0   \n",
       "188924           5.37   0.0   0.0         3.9   NaN    58    30  0.0      0.0   \n",
       "\n",
       "        SLEET_OR_HAIL  month  year  \n",
       "177784            0.0      1  2016  \n",
       "177785            0.0      1  2016  \n",
       "177786            0.0      1  2016  \n",
       "177787            0.0      1  2016  \n",
       "177788            0.0      1  2016  \n",
       "...               ...    ...   ...  \n",
       "188920            0.0      1  2016  \n",
       "188921            0.0      1  2016  \n",
       "188922            0.0      1  2016  \n",
       "188923            0.0      1  2016  \n",
       "188924            0.0      1  2016  \n",
       "\n",
       "[11141 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVG_WND_SPEED</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>FOG</th>\n",
       "      <th>THUNDER</th>\n",
       "      <th>SLEET_OR_HAIL</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, DATE, start_station_id, hour_of_day, COUNT, AVG_WND_SPEED, PRCP, SNOW, SNOW_DEPTH, TAVG, TMAX, TMIN, FOG, THUNDER, SLEET_OR_HAIL, month, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['TAVG'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TAVG'] = df.apply(lambda row: ((row['TMAX']+row['TMIN'])/2) if np.isnan(row['TAVG']) else row['TAVG'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVG_WND_SPEED</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>FOG</th>\n",
       "      <th>THUNDER</th>\n",
       "      <th>SLEET_OR_HAIL</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2015-04-23</td>\n",
       "      <td>3004.0</td>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>15.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444211</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444212</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444213</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444214</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1444215</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>3210.0</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>7.61</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>75</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444216 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE  start_station_id  hour_of_day  COUNT  AVG_WND_SPEED  \\\n",
       "0        2015-04-23            3004.0           10      5          15.21   \n",
       "1        2015-04-23            3004.0           12      3          15.21   \n",
       "2        2015-04-23            3004.0           13      2          15.21   \n",
       "3        2015-04-23            3004.0           14      1          15.21   \n",
       "4        2015-04-23            3004.0           15      5          15.21   \n",
       "...             ...               ...          ...    ...            ...   \n",
       "1444211  2019-09-30            3210.0            9      3           7.61   \n",
       "1444212  2019-09-30            3210.0           10      1           7.61   \n",
       "1444213  2019-09-30            3210.0           11      1           7.61   \n",
       "1444214  2019-09-30            3210.0           12      1           7.61   \n",
       "1444215  2019-09-30            3210.0           17      4           7.61   \n",
       "\n",
       "         PRCP  SNOW  SNOW_DEPTH  TAVG  TMAX  TMIN  FOG  THUNDER  \\\n",
       "0         0.0   0.0         0.0  48.0    52    43  0.0      0.0   \n",
       "1         0.0   0.0         0.0  48.0    52    43  0.0      0.0   \n",
       "2         0.0   0.0         0.0  48.0    52    43  0.0      0.0   \n",
       "3         0.0   0.0         0.0  48.0    52    43  0.0      0.0   \n",
       "4         0.0   0.0         0.0  48.0    52    43  0.0      0.0   \n",
       "...       ...   ...         ...   ...   ...   ...  ...      ...   \n",
       "1444211   0.0   0.0         0.0  69.0    75    62  0.0      0.0   \n",
       "1444212   0.0   0.0         0.0  69.0    75    62  0.0      0.0   \n",
       "1444213   0.0   0.0         0.0  69.0    75    62  0.0      0.0   \n",
       "1444214   0.0   0.0         0.0  69.0    75    62  0.0      0.0   \n",
       "1444215   0.0   0.0         0.0  69.0    75    62  0.0      0.0   \n",
       "\n",
       "         SLEET_OR_HAIL  month  year  \n",
       "0                  0.0      4  2015  \n",
       "1                  0.0      4  2015  \n",
       "2                  0.0      4  2015  \n",
       "3                  0.0      4  2015  \n",
       "4                  0.0      4  2015  \n",
       "...                ...    ...   ...  \n",
       "1444211            0.0      9  2019  \n",
       "1444212            0.0      9  2019  \n",
       "1444213            0.0      9  2019  \n",
       "1444214            0.0      9  2019  \n",
       "1444215            0.0      9  2019  \n",
       "\n",
       "[1444216 rows x 16 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>DATE</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVG_WND_SPEED</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>SNOW</th>\n",
       "      <th>SNOW_DEPTH</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>FOG</th>\n",
       "      <th>THUNDER</th>\n",
       "      <th>SLEET_OR_HAIL</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Unnamed: 0, DATE, start_station_id, hour_of_day, COUNT, AVG_WND_SPEED, PRCP, SNOW, SNOW_DEPTH, TAVG, TMAX, TMIN, FOG, THUNDER, SLEET_OR_HAIL, month, year]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DATE', 'start_station_id', 'hour_of_day', 'COUNT',\n",
       "       'AVG_WND_SPEED', 'PRCP', 'SNOW', 'SNOW_DEPTH', 'TAVG', 'TMAX',\n",
       "       'TMIN', 'FOG', 'THUNDER', 'SLEET_OR_HAIL', 'month', 'year'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"final_data_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['start_station_id', 'hour_of_day', 'AVG_WND_SPEED', 'PRCP', 'SNOW', 'SNOW_DEPTH', 'TAVG', 'TMAX', 'TMIN', 'FOG', 'THUNDER', 'SLEET_OR_HAIL', 'month', 'year']]\n",
    "y = df['COUNT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor,MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(5,5), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.79167245\n",
      "Iteration 2, loss = 1.45893714\n",
      "Iteration 3, loss = 1.45722796\n",
      "Iteration 4, loss = 1.45598925\n",
      "Iteration 5, loss = 1.45499267\n",
      "Iteration 6, loss = 1.45395484\n",
      "Iteration 7, loss = 1.45243746\n",
      "Iteration 8, loss = 1.44918986\n",
      "Iteration 9, loss = 1.44595335\n",
      "Iteration 10, loss = 1.44366823\n",
      "Iteration 11, loss = 1.43981285\n",
      "Iteration 12, loss = 1.43924099\n",
      "Iteration 13, loss = 1.43875277\n",
      "Iteration 14, loss = 1.43849801\n",
      "Iteration 15, loss = 1.43829583\n",
      "Iteration 16, loss = 1.43820892\n",
      "Iteration 17, loss = 1.43789245\n",
      "Iteration 18, loss = 1.43800996\n",
      "Iteration 19, loss = 1.43789496\n",
      "Iteration 20, loss = 1.43754706\n",
      "Iteration 21, loss = 1.43759740\n",
      "Iteration 22, loss = 1.43759369\n",
      "Iteration 23, loss = 1.43751020\n",
      "Iteration 24, loss = 1.43760957\n",
      "Iteration 25, loss = 1.43743637\n",
      "Iteration 26, loss = 1.43740419\n",
      "Iteration 27, loss = 1.43734547\n",
      "Iteration 28, loss = 1.43709565\n",
      "Iteration 29, loss = 1.43727206\n",
      "Iteration 30, loss = 1.43728615\n",
      "Iteration 31, loss = 1.43729403\n",
      "Iteration 32, loss = 1.43718351\n",
      "Iteration 33, loss = 1.43701290\n",
      "Iteration 34, loss = 1.43698491\n",
      "Iteration 35, loss = 1.43692652\n",
      "Iteration 36, loss = 1.43715709\n",
      "Iteration 37, loss = 1.43679729\n",
      "Iteration 38, loss = 1.43704585\n",
      "Iteration 39, loss = 1.43693936\n",
      "Iteration 40, loss = 1.43709276\n",
      "Iteration 41, loss = 1.43688242\n",
      "Iteration 42, loss = 1.43703225\n",
      "Iteration 43, loss = 1.43697727\n",
      "Iteration 44, loss = 1.43677106\n",
      "Iteration 45, loss = 1.43699206\n",
      "Iteration 46, loss = 1.43686071\n",
      "Iteration 47, loss = 1.43684488\n",
      "Iteration 48, loss = 1.43688128\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(5, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'mlp_model_1.pkl'\n",
    "pickle.dump(mlp, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5073257536940355"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[146538      0      0 ...      0      0      0]\n",
      " [ 66838      0      0 ...      0      0      0]\n",
      " [ 32417      0      0 ...      0      0      0]\n",
      " ...\n",
      " [     1      0      0 ...      0      0      0]\n",
      " [     1      0      0 ...      0      0      0]\n",
      " [     1      0      0 ...      0      0      0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      1.00      0.67    146538\n",
      "           2       0.00      0.00      0.00     66838\n",
      "           3       0.00      0.00      0.00     32417\n",
      "           4       0.00      0.00      0.00     17235\n",
      "           5       0.00      0.00      0.00      9804\n",
      "           6       0.00      0.00      0.00      5611\n",
      "           7       0.00      0.00      0.00      3547\n",
      "           8       0.00      0.00      0.00      2290\n",
      "           9       0.00      0.00      0.00      1410\n",
      "          10       0.00      0.00      0.00       959\n",
      "          11       0.00      0.00      0.00       665\n",
      "          12       0.00      0.00      0.00       443\n",
      "          13       0.00      0.00      0.00       297\n",
      "          14       0.00      0.00      0.00       205\n",
      "          15       0.00      0.00      0.00       144\n",
      "          16       0.00      0.00      0.00       106\n",
      "          17       0.00      0.00      0.00        71\n",
      "          18       0.00      0.00      0.00        51\n",
      "          19       0.00      0.00      0.00        43\n",
      "          20       0.00      0.00      0.00        31\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00        18\n",
      "          23       0.00      0.00      0.00        11\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00        14\n",
      "          27       0.00      0.00      0.00         5\n",
      "          28       0.00      0.00      0.00         7\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         5\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51    288844\n",
      "   macro avg       0.01      0.02      0.02    288844\n",
      "weighted avg       0.26      0.51      0.34    288844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2 = MLPClassifier(hidden_layer_sizes=(10,5), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.63765733\n",
      "Iteration 2, loss = 1.47629496\n",
      "Iteration 3, loss = 1.46884533\n",
      "Iteration 4, loss = 1.46667778\n",
      "Iteration 5, loss = 1.46313820\n",
      "Iteration 6, loss = 1.46138473\n",
      "Iteration 7, loss = 1.46035121\n",
      "Iteration 8, loss = 1.46048141\n",
      "Iteration 9, loss = 1.46002725\n",
      "Iteration 10, loss = 1.45992043\n",
      "Iteration 11, loss = 1.45999382\n",
      "Iteration 12, loss = 1.45965549\n",
      "Iteration 13, loss = 1.45987536\n",
      "Iteration 14, loss = 1.45943217\n",
      "Iteration 15, loss = 1.45930867\n",
      "Iteration 16, loss = 1.45915473\n",
      "Iteration 17, loss = 1.45836225\n",
      "Iteration 18, loss = 1.45720097\n",
      "Iteration 19, loss = 1.45715809\n",
      "Iteration 20, loss = 1.45658178\n",
      "Iteration 21, loss = 1.45677835\n",
      "Iteration 22, loss = 1.45627459\n",
      "Iteration 23, loss = 1.45671946\n",
      "Iteration 24, loss = 1.45594825\n",
      "Iteration 25, loss = 1.45581268\n",
      "Iteration 26, loss = 1.45609079\n",
      "Iteration 27, loss = 1.45599908\n",
      "Iteration 28, loss = 1.45542047\n",
      "Iteration 29, loss = 1.45551428\n",
      "Iteration 30, loss = 1.45510158\n",
      "Iteration 31, loss = 1.45361194\n",
      "Iteration 32, loss = 1.45346332\n",
      "Iteration 33, loss = 1.45311532\n",
      "Iteration 34, loss = 1.45307222\n",
      "Iteration 35, loss = 1.45258459\n",
      "Iteration 36, loss = 1.45206248\n",
      "Iteration 37, loss = 1.45149898\n",
      "Iteration 38, loss = 1.45035491\n",
      "Iteration 39, loss = 1.44756209\n",
      "Iteration 40, loss = 1.44314796\n",
      "Iteration 41, loss = 1.44031445\n",
      "Iteration 42, loss = 1.43913007\n",
      "Iteration 43, loss = 1.43853102\n",
      "Iteration 44, loss = 1.43783781\n",
      "Iteration 45, loss = 1.43770027\n",
      "Iteration 46, loss = 1.43753753\n",
      "Iteration 47, loss = 1.43752477\n",
      "Iteration 48, loss = 1.43751989\n",
      "Iteration 49, loss = 1.43723808\n",
      "Iteration 50, loss = 1.43699026\n",
      "Iteration 51, loss = 1.43699726\n",
      "Iteration 52, loss = 1.43716833\n",
      "Iteration 53, loss = 1.43700665\n",
      "Iteration 54, loss = 1.43714745\n",
      "Iteration 55, loss = 1.43724834\n",
      "Iteration 56, loss = 1.43719552\n",
      "Iteration 57, loss = 1.43707460\n",
      "Iteration 58, loss = 1.43702753\n",
      "Iteration 59, loss = 1.43684157\n",
      "Iteration 60, loss = 1.43693622\n",
      "Iteration 61, loss = 1.43693790\n",
      "Iteration 62, loss = 1.43707493\n",
      "Iteration 63, loss = 1.43689313\n",
      "Iteration 64, loss = 1.43649707\n",
      "Iteration 65, loss = 1.43682095\n",
      "Iteration 66, loss = 1.43672944\n",
      "Iteration 67, loss = 1.43680617\n",
      "Iteration 68, loss = 1.43699655\n",
      "Iteration 69, loss = 1.43681096\n",
      "Iteration 70, loss = 1.43674362\n",
      "Iteration 71, loss = 1.43696286\n",
      "Iteration 72, loss = 1.43689403\n",
      "Iteration 73, loss = 1.43679161\n",
      "Iteration 74, loss = 1.43638484\n",
      "Iteration 75, loss = 1.43661909\n",
      "Iteration 76, loss = 1.43682144\n",
      "Iteration 77, loss = 1.43627277\n",
      "Iteration 78, loss = 1.43673350\n",
      "Iteration 79, loss = 1.43660273\n",
      "Iteration 80, loss = 1.43656807\n",
      "Iteration 81, loss = 1.43687122\n",
      "Iteration 82, loss = 1.43658242\n",
      "Iteration 83, loss = 1.43676307\n",
      "Iteration 84, loss = 1.43651650\n",
      "Iteration 85, loss = 1.43652689\n",
      "Iteration 86, loss = 1.43646524\n",
      "Iteration 87, loss = 1.43649213\n",
      "Iteration 88, loss = 1.43653802\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mlp_model_2.pkl'\n",
    "pickle.dump(mlp2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5073257536940355"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      1.00      0.67    146538\n",
      "           2       0.00      0.00      0.00     66838\n",
      "           3       0.00      0.00      0.00     32417\n",
      "           4       0.00      0.00      0.00     17235\n",
      "           5       0.00      0.00      0.00      9804\n",
      "           6       0.00      0.00      0.00      5611\n",
      "           7       0.00      0.00      0.00      3547\n",
      "           8       0.00      0.00      0.00      2290\n",
      "           9       0.00      0.00      0.00      1410\n",
      "          10       0.00      0.00      0.00       959\n",
      "          11       0.00      0.00      0.00       665\n",
      "          12       0.00      0.00      0.00       443\n",
      "          13       0.00      0.00      0.00       297\n",
      "          14       0.00      0.00      0.00       205\n",
      "          15       0.00      0.00      0.00       144\n",
      "          16       0.00      0.00      0.00       106\n",
      "          17       0.00      0.00      0.00        71\n",
      "          18       0.00      0.00      0.00        51\n",
      "          19       0.00      0.00      0.00        43\n",
      "          20       0.00      0.00      0.00        31\n",
      "          21       0.00      0.00      0.00        27\n",
      "          22       0.00      0.00      0.00        18\n",
      "          23       0.00      0.00      0.00        11\n",
      "          24       0.00      0.00      0.00        15\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00        14\n",
      "          27       0.00      0.00      0.00         5\n",
      "          28       0.00      0.00      0.00         7\n",
      "          29       0.00      0.00      0.00         5\n",
      "          30       0.00      0.00      0.00         4\n",
      "          31       0.00      0.00      0.00         4\n",
      "          32       0.00      0.00      0.00         5\n",
      "          33       0.00      0.00      0.00         1\n",
      "          34       0.00      0.00      0.00         2\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          49       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.51    288844\n",
      "   macro avg       0.01      0.02      0.02    288844\n",
      "weighted avg       0.26      0.51      0.34    288844\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = mlp2.predict(X_test)\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp3 = MLPRegressor(hidden_layer_sizes=(10,5), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2400.63327841\n",
      "Iteration 2, loss = 1.86544076\n",
      "Iteration 3, loss = 1.98440646\n",
      "Iteration 4, loss = 2.06947360\n",
      "Iteration 5, loss = 1.91111774\n",
      "Iteration 6, loss = 2.30315300\n",
      "Iteration 7, loss = 2.09342067\n",
      "Iteration 8, loss = 1.87194204\n",
      "Iteration 9, loss = 1.88380286\n",
      "Iteration 10, loss = 1.82485433\n",
      "Iteration 11, loss = 1.83340522\n",
      "Iteration 12, loss = 1.80221010\n",
      "Iteration 13, loss = 1.79531356\n",
      "Iteration 14, loss = 1.80312311\n",
      "Iteration 15, loss = 1.79192900\n",
      "Iteration 16, loss = 1.79108654\n",
      "Iteration 17, loss = 1.78597249\n",
      "Iteration 18, loss = 1.78371065\n",
      "Iteration 19, loss = 1.77861450\n",
      "Iteration 20, loss = 1.77071766\n",
      "Iteration 21, loss = 1.76669202\n",
      "Iteration 22, loss = 1.76327526\n",
      "Iteration 23, loss = 1.76130989\n",
      "Iteration 24, loss = 1.75995113\n",
      "Iteration 25, loss = 1.75914125\n",
      "Iteration 26, loss = 1.75866558\n",
      "Iteration 27, loss = 1.75744962\n",
      "Iteration 28, loss = 1.75641920\n",
      "Iteration 29, loss = 1.75571636\n",
      "Iteration 30, loss = 1.75410286\n",
      "Iteration 31, loss = 1.75225933\n",
      "Iteration 32, loss = 1.74948915\n",
      "Iteration 33, loss = 1.73109044\n",
      "Iteration 34, loss = 1.71407259\n",
      "Iteration 35, loss = 1.71056532\n",
      "Iteration 36, loss = 1.70843646\n",
      "Iteration 37, loss = 1.70757723\n",
      "Iteration 38, loss = 1.70682914\n",
      "Iteration 39, loss = 1.70540295\n",
      "Iteration 40, loss = 1.70559383\n",
      "Iteration 41, loss = 1.70540067\n",
      "Iteration 42, loss = 1.70519756\n",
      "Iteration 43, loss = 1.70458994\n",
      "Iteration 44, loss = 1.70427161\n",
      "Iteration 45, loss = 1.70398121\n",
      "Iteration 46, loss = 1.70424755\n",
      "Iteration 47, loss = 1.70393573\n",
      "Iteration 48, loss = 1.70262214\n",
      "Iteration 49, loss = 1.70133682\n",
      "Iteration 50, loss = 1.70124172\n",
      "Iteration 51, loss = 1.70066919\n",
      "Iteration 52, loss = 1.70075449\n",
      "Iteration 53, loss = 1.70077360\n",
      "Iteration 54, loss = 1.70079781\n",
      "Iteration 55, loss = 1.70027101\n",
      "Iteration 56, loss = 1.70041812\n",
      "Iteration 57, loss = 1.70034498\n",
      "Iteration 58, loss = 1.70015337\n",
      "Iteration 59, loss = 1.70009695\n",
      "Iteration 60, loss = 1.69976940\n",
      "Iteration 61, loss = 1.69995509\n",
      "Iteration 62, loss = 1.69976570\n",
      "Iteration 63, loss = 1.69959581\n",
      "Iteration 64, loss = 1.69938046\n",
      "Iteration 65, loss = 1.70002679\n",
      "Iteration 66, loss = 1.69934320\n",
      "Iteration 67, loss = 1.69979466\n",
      "Iteration 68, loss = 1.69904225\n",
      "Iteration 69, loss = 1.69936939\n",
      "Iteration 70, loss = 1.70011465\n",
      "Iteration 71, loss = 1.69934824\n",
      "Iteration 72, loss = 1.69975063\n",
      "Iteration 73, loss = 1.69932492\n",
      "Iteration 74, loss = 1.69902372\n",
      "Iteration 75, loss = 1.69921421\n",
      "Iteration 76, loss = 1.69891095\n",
      "Iteration 77, loss = 1.69850701\n",
      "Iteration 78, loss = 1.69907299\n",
      "Iteration 79, loss = 1.69859407\n",
      "Iteration 80, loss = 1.69859799\n",
      "Iteration 81, loss = 1.69872209\n",
      "Iteration 82, loss = 1.69897170\n",
      "Iteration 83, loss = 1.69866074\n",
      "Iteration 84, loss = 1.69877400\n",
      "Iteration 85, loss = 1.69861547\n",
      "Iteration 86, loss = 1.69848284\n",
      "Iteration 87, loss = 1.69924608\n",
      "Iteration 88, loss = 1.69795550\n",
      "Iteration 89, loss = 1.69851768\n",
      "Iteration 90, loss = 1.69861787\n",
      "Iteration 91, loss = 1.69850942\n",
      "Iteration 92, loss = 1.69827461\n",
      "Iteration 93, loss = 1.69826560\n",
      "Iteration 94, loss = 1.69817725\n",
      "Iteration 95, loss = 1.69844988\n",
      "Iteration 96, loss = 1.69841858\n",
      "Iteration 97, loss = 1.69831673\n",
      "Iteration 98, loss = 1.69798167\n",
      "Iteration 99, loss = 1.69825772\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "             beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "             hidden_layer_sizes=(10, 5), learning_rate='constant',\n",
       "             learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "             n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "             random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07030668948407381"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'mlp_model_3.pkl'\n",
    "pickle.dump(mlp3, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp4 = MLPClassifier(hidden_layer_sizes=(10,5,7), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = inf\n",
      "Iteration 2, loss = 1.46310334\n",
      "Iteration 3, loss = 1.46125016\n",
      "Iteration 4, loss = 1.45969324\n",
      "Iteration 5, loss = 1.45781339\n",
      "Iteration 6, loss = 1.45839183\n",
      "Iteration 7, loss = 1.45656542\n",
      "Iteration 8, loss = 1.45490153\n",
      "Iteration 9, loss = 1.45299250\n",
      "Iteration 10, loss = 1.45138370\n",
      "Iteration 11, loss = 1.45002971\n",
      "Iteration 12, loss = 1.44862914\n",
      "Iteration 13, loss = 1.44758050\n",
      "Iteration 14, loss = 1.44597927\n",
      "Iteration 15, loss = 1.44454350\n",
      "Iteration 16, loss = 1.44323162\n",
      "Iteration 17, loss = 1.44199991\n",
      "Iteration 18, loss = 1.44115005\n",
      "Iteration 19, loss = 1.44030096\n",
      "Iteration 20, loss = 1.43972780\n",
      "Iteration 21, loss = 1.43931380\n",
      "Iteration 22, loss = 1.43887893\n",
      "Iteration 23, loss = 1.43858267\n",
      "Iteration 24, loss = 1.43828475\n",
      "Iteration 25, loss = 1.43797850\n",
      "Iteration 26, loss = 1.43778243\n",
      "Iteration 27, loss = 1.43755034\n",
      "Iteration 28, loss = 1.43720857\n",
      "Iteration 29, loss = 1.43714609\n",
      "Iteration 30, loss = 1.43679498\n",
      "Iteration 31, loss = 1.43658784\n",
      "Iteration 32, loss = 1.43648111\n",
      "Iteration 33, loss = 1.43660897\n",
      "Iteration 34, loss = 1.43617955\n",
      "Iteration 35, loss = 1.43641463\n",
      "Iteration 36, loss = 1.43633325\n",
      "Iteration 37, loss = 1.43534138\n",
      "Iteration 38, loss = 1.43475148\n",
      "Iteration 39, loss = 1.43440223\n",
      "Iteration 40, loss = 1.43319302\n",
      "Iteration 41, loss = 1.43211279\n",
      "Iteration 42, loss = 1.43131872\n",
      "Iteration 43, loss = 1.43087007\n",
      "Iteration 44, loss = 1.43030143\n",
      "Iteration 45, loss = 1.43017513\n",
      "Iteration 46, loss = 1.42963300\n",
      "Iteration 47, loss = 1.42923980\n",
      "Iteration 48, loss = 1.42923001\n",
      "Iteration 49, loss = 1.42911848\n",
      "Iteration 50, loss = 1.42897058\n",
      "Iteration 51, loss = 1.42880353\n",
      "Iteration 52, loss = 1.42855494\n",
      "Iteration 53, loss = 1.42843957\n",
      "Iteration 54, loss = 1.42834351\n",
      "Iteration 55, loss = 1.42795947\n",
      "Iteration 56, loss = 1.42792620\n",
      "Iteration 57, loss = 1.42817127\n",
      "Iteration 58, loss = 1.42759777\n",
      "Iteration 59, loss = 1.42764987\n",
      "Iteration 60, loss = 1.42766583\n",
      "Iteration 61, loss = 1.42733296\n",
      "Iteration 62, loss = 1.42739060\n",
      "Iteration 63, loss = 1.42774006\n",
      "Iteration 64, loss = 1.42703383\n",
      "Iteration 65, loss = 1.42708092\n",
      "Iteration 66, loss = 1.42725134\n",
      "Iteration 67, loss = 1.42674329\n",
      "Iteration 68, loss = 1.42679876\n",
      "Iteration 69, loss = 1.42680271\n",
      "Iteration 70, loss = 1.42705465\n",
      "Iteration 71, loss = 1.42699810\n",
      "Iteration 72, loss = 1.42703207\n",
      "Iteration 73, loss = 1.42696302\n",
      "Iteration 74, loss = 1.42693107\n",
      "Iteration 75, loss = 1.42674870\n",
      "Iteration 76, loss = 1.42694696\n",
      "Iteration 77, loss = 1.42680610\n",
      "Iteration 78, loss = 1.42651718\n",
      "Iteration 79, loss = 1.42655935\n",
      "Iteration 80, loss = 1.42647990\n",
      "Iteration 81, loss = 1.42671201\n",
      "Iteration 82, loss = 1.42630458\n",
      "Iteration 83, loss = 1.42627915\n",
      "Iteration 84, loss = 1.42629722\n",
      "Iteration 85, loss = 1.42673644\n",
      "Iteration 86, loss = 1.42634791\n",
      "Iteration 87, loss = 1.42621050\n",
      "Iteration 88, loss = 1.42636319\n",
      "Iteration 89, loss = 1.42664840\n",
      "Iteration 90, loss = 1.42653822\n",
      "Iteration 91, loss = 1.42623469\n",
      "Iteration 92, loss = 1.42630496\n",
      "Iteration 93, loss = 1.42644312\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(10, 5, 7), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5073257536940355"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5 = MLPClassifier(hidden_layer_sizes=(12,7,7,5), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.81454278\n",
      "Iteration 2, loss = 1.46018314\n",
      "Iteration 3, loss = 1.45825017\n",
      "Iteration 4, loss = 1.45704788\n",
      "Iteration 5, loss = 1.45575725\n",
      "Iteration 6, loss = 1.45177442\n",
      "Iteration 7, loss = 1.43860126\n",
      "Iteration 8, loss = 1.43413589\n",
      "Iteration 9, loss = 1.43242907\n",
      "Iteration 10, loss = 1.43070224\n",
      "Iteration 11, loss = 1.42933547\n",
      "Iteration 12, loss = 1.42776737\n",
      "Iteration 13, loss = 1.42713985\n",
      "Iteration 14, loss = 1.42603348\n",
      "Iteration 15, loss = 1.42537318\n",
      "Iteration 16, loss = 1.42525265\n",
      "Iteration 17, loss = 1.42417362\n",
      "Iteration 18, loss = 1.42399008\n",
      "Iteration 19, loss = 1.42367708\n",
      "Iteration 20, loss = 1.42306586\n",
      "Iteration 21, loss = 1.42361200\n",
      "Iteration 22, loss = 1.42253144\n",
      "Iteration 23, loss = 1.42243021\n",
      "Iteration 24, loss = 1.42231419\n",
      "Iteration 25, loss = 1.42160888\n",
      "Iteration 26, loss = 1.42168416\n",
      "Iteration 27, loss = 1.42124255\n",
      "Iteration 28, loss = 1.42115860\n",
      "Iteration 29, loss = 1.42073848\n",
      "Iteration 30, loss = 1.42062544\n",
      "Iteration 31, loss = 1.41982830\n",
      "Iteration 32, loss = 1.41958971\n",
      "Iteration 33, loss = 1.41941630\n",
      "Iteration 34, loss = 1.41918649\n",
      "Iteration 35, loss = 1.41875635\n",
      "Iteration 36, loss = 1.41857131\n",
      "Iteration 37, loss = 1.41867606\n",
      "Iteration 38, loss = 1.41826349\n",
      "Iteration 39, loss = 1.41815056\n",
      "Iteration 40, loss = 1.41772267\n",
      "Iteration 41, loss = 1.41763621\n",
      "Iteration 42, loss = 1.41738341\n",
      "Iteration 43, loss = 1.41778365\n",
      "Iteration 44, loss = 1.41746049\n",
      "Iteration 45, loss = 1.41741042\n",
      "Iteration 46, loss = 1.41757424\n",
      "Iteration 47, loss = 1.41724743\n",
      "Iteration 48, loss = 1.41727208\n",
      "Iteration 49, loss = 1.41734523\n",
      "Iteration 50, loss = 1.41742576\n",
      "Iteration 51, loss = 1.41689037\n",
      "Iteration 52, loss = 1.41728970\n",
      "Iteration 53, loss = 1.41693472\n",
      "Iteration 54, loss = 1.41689312\n",
      "Iteration 55, loss = 1.41717166\n",
      "Iteration 56, loss = 1.41692583\n",
      "Iteration 57, loss = 1.41700525\n",
      "Iteration 58, loss = 1.41696084\n",
      "Iteration 59, loss = 1.41672556\n",
      "Iteration 60, loss = 1.41661474\n",
      "Iteration 61, loss = 1.41692174\n",
      "Iteration 62, loss = 1.41686738\n",
      "Iteration 63, loss = 1.41658505\n",
      "Iteration 64, loss = 1.41661581\n",
      "Iteration 65, loss = 1.41657709\n",
      "Iteration 66, loss = 1.41676698\n",
      "Iteration 67, loss = 1.41669329\n",
      "Iteration 68, loss = 1.41653267\n",
      "Iteration 69, loss = 1.41666824\n",
      "Iteration 70, loss = 1.41627942\n",
      "Iteration 71, loss = 1.41665138\n",
      "Iteration 72, loss = 1.41660611\n",
      "Iteration 73, loss = 1.41649798\n",
      "Iteration 74, loss = 1.41645361\n",
      "Iteration 75, loss = 1.41649706\n",
      "Iteration 76, loss = 1.41658713\n",
      "Iteration 77, loss = 1.41650529\n",
      "Iteration 78, loss = 1.41656813\n",
      "Iteration 79, loss = 1.41641024\n",
      "Iteration 80, loss = 1.41650938\n",
      "Iteration 81, loss = 1.41641407\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(12, 7, 7, 5), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=3, warm_start=False)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp5.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp5.score(X_test, y_test)\n",
    "filename = 'mlp_model_5.pkl'\n",
    "pickle.dump(mlp5, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rebecca/anaconda3/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:23] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
       "             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "             silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try xgboost\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# fit model no training data\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19218245165892955"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
